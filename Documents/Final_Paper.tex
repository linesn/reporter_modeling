
\documentclass{amsart}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsfonts}
\usepackage{hyperref}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=BibTeX}
%TCIDATA{Created=Thursday, May 12, 2022 21:29:02}
%TCIDATA{LastRevised=Friday, May 13, 2022 15:25:29}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Articles\SW\AMS Journal Article">}
%TCIDATA{CSTFile=amsartci.cst}

\newtheorem{theorem}{Theorem}
\theoremstyle{plain}
\newtheorem{acknowledgement}{Acknowledgement}
\newtheorem{algorithm}{Algorithm}
\newtheorem{axiom}{Axiom}
\newtheorem{case}{Case}
\newtheorem{claim}{Claim}
\newtheorem{conclusion}{Conclusion}
\newtheorem{condition}{Condition}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{criterion}{Criterion}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{exercise}{Exercise}
\newtheorem{lemma}{Lemma}
\newtheorem{notation}{Notation}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{solution}{Solution}
\newtheorem{summary}{Summary}
\numberwithin{equation}{section}
\input{tcilatex}

\begin{document}
\title[News Reporting]{A Bayesian Model for News Reporting}
\author{Nicholas A. Lines}
\address{}
\email[N. Lines]{nicholasalines@gmail.com}
\urladdr{https://github.com/linesn/reporter\_modeling}
\thanks{The author would like to thank Dr. Woolf for advising this project,
as well as the author's friend Rod Gomez for his advice regarding PyMC3.}
\date{May 12, 2022}
\thanks{This paper is part of the author's final project for
EN.625.692.81.SP22 Probabilistic Graphical Models, for Johns Hopkins
University.}

\begin{abstract}
Replace this text with your own abstract.
\end{abstract}

\maketitle
\tableofcontents
\listoffigures

\newpage

\section{Modeling Information Collation and Reporting}

Anyone with a social media account and internet connection can expect to be
bombarded by information, opinions, and news. On an individual level,
accumulating important news information is overwhelmingly done through
passive online activities. Five years ago the Pew Research Center found that
67\% of Americans learned about news on social media, and this year they
added that 23\% got their news from podcasts \cite{gottfried2019news}\cite%
{walker2022nearly}. Interestingly, this movement toward digitally-fed news
has also brought on increased concern about legitimacy: Pew also asked their
2021 respondents if they would support Federal internet censorship, and 48\%
said yes, compared with 39\% in 2018. How to use existing systems to find
credible information is a vital question each individual must answer. More
generally, any actor involved in distilling news data into factual reports
must perform a similar credibility analysis using a network of dubious
sources. Self-filtering news data is a difficult challenge, involving both
bias in the sources consulted, bias introduced by those sources, and bias in
credibility assessment introduced by the actor.

In this paper we introduce a probabilistic graphical framework in which we
can explore information fusion tasks. This proposed approach is elementary,
but it has the potential to develop as a tool to compliment human
credibility assessment of news information sources. We note that the goal of
our investigation is to improve in recognition of net credibility of sources
in terms of \emph{consensus}, not \emph{truth}. We will model a general
information fusion task and demonstrate several approaches for reducing
input from untrusted sources, and discuss variations of this problem and its
applications.

\section{Related Work}

In recent years, efforts to understand how news information propagates in a
network have largely focused on social networks. In \cite%
{zafarani2015evaluation} we find this problem approached in a way that
explicitly admits that ground truth is unavailable, which inspired our
consensus-based approach. In many applications, including digestion of news
information, ground truth is unavailable, and consensus of a class of
observers or experts is considered its best approximation. Consensus-based
modeling of one kind or other fills an increasingly important role in
medical research and practice \cite{fink1984consensus}, blockchain protocols 
\cite{sankar2017survey}, and other multi-agent systems \cite{ren2005survey}.

Social media analysis frequently turns to consensus-based approaches with
success. This is evident in applications such as trust exploration \cite%
{heuer2018trust}, and efforts to characterize social dynamics to gauge
adoption of new technology, like in \cite{kohler2001density}. We emphasize
that consensus-based approaches have great potential for misinterpretation
and abuse in social (particularly news analysis)\ settings. Discarding
disagreements from consensus in these settings may ignore early warnings,
marginalized social groups, or expert opinions, and may obscure the true
evolution of opinion. We urge that these methods be applied with caution and
intentionally used to filter noise under careful supervision.

Analysis of how credibility is changed within a network of communicating
agents is often connected to the concept of belief propagation, a term used
both for the idea in general of spreading beliefs, but also specifically
applied to the sum-product algorithm for this purpose pioneered by Judea
Pearl. A useful survey on this subject is provided in \cite%
{yedidia2003understanding}.

Storing and using knowledge in a probabilistic graphical framework is
usually the realm of knowledge graphs. For a fairly thorough source that
introduces knowledge graphs and their applications, we refer to \cite%
{hogan2021knowledge}. Another name this problem falls under is "information
fusion," which has begun to be applied to text-based problems as well (see 
\cite{levchuk2015probabilistic} and \cite{radev2000common}).

\section{A Bayesian Network Model}

To motivate our model and the related inference problems, we will consider
the following common situation. A news analyst is tasked with understanding
and summarizing news over time, covering several news topics. This analyst
is disconnected from the actual chain of events of interest, and relies
entirely on a set of first-hand observers to pass on reports about these
topics. However, not all observers are alike. Some are more apt to report
information than others. Some are more aware of a particular news topic than
others. We will make the (significant) assumption that a consensus of
observers represents accepted fact for the analyst. The analyst's principal
task is to identify observations held in consensus and report these.
Secondarily, the analyst wishes to "weed out" observations that are
unhelpful. If an observer consistently disagrees with the general consensus
on a topic, that observer does not need to be surveyed on that topic, or
perhaps their response should be weighted low, proportionate in some way to
the trust they have acrued.

We will now introduce a Bayesian network that generatively models this
situation with certain constraints. In particular we will only consider
binary facts related to each topic.

\begin{definition}
Reporter Model A: Let $n_{j}$ be the number of news topics of interest, $%
n_{i}$ the number of observers, and $n_{t}$ the number of timesteps in the
modeled timeframe. For each topic $j=1,\dots ,n_{j}$ we assume that news
topic has a bias 
\begin{equation*}
\delta _{j}\sim ~Uniform\left( 0,1\right)
\end{equation*}%
that indicates preference toward a fact value of $1$. At each time step $%
t=1,\dots ,n_{t}$ a new fact is generated%
\begin{equation*}
f_{j,t}\sim ~Bernoulli\left( \delta _{j}\right) .
\end{equation*}%
Each observer $i=1,\dots ,n_{i}$ has a bias that indicates how willing they
are to report their observations about this topic,%
\begin{equation*}
\varepsilon _{i,j}\sim ~Uniform\left( 0,1\right) ,
\end{equation*}%
and an awareness level for this topic,%
\begin{equation*}
\beta _{i,j}\sim ~Uniform\left( 0,1\right) .
\end{equation*}%
At each timestep they draw a decision about whether to report%
\begin{equation*}
\tau _{i,j,t}\sim ~Bernoulli\left( \varepsilon _{i,j}\right)
\end{equation*}%
and draw to decide if they are aware of the current fact%
\begin{equation*}
\alpha _{i,j,t}\sim ~Bernoulli\left( \beta _{i,j}\right) .
\end{equation*}%
We also generate random noise 
\begin{equation*}
r_{i,j,t}\sim ~Bernoulli\left( \frac{1}{2}\right) .
\end{equation*}%
The observer then computes%
\begin{equation*}
o_{i,j,t}=\tau _{i,j,t}\left( \alpha _{i,j,t}f_{j,t}+\left( 1-\alpha
_{i,j,t}r_{i,j,t}\right) \right) +2\left( 1-\tau _{i,j,t}\right)
\end{equation*}%
which is their observation passed on to the analyst. This means that if
observer is aware and willing to report, they pass on the true fact. If they
are aware but unwilling to report, they pass on the value $2$, which means
nothing was reported. If they are willing to report but unaware of the fact,
they report the random noise.

The analyst at each time step computes the vote $b_{j,t}=\limfunc{mode}%
\left( \left\{ o_{i,j,t}:o_{i,j,t}\neq 2\right\} \right) $, which represents
the consensus for fact $f_{j,t}$. This model is presented as a plate diagram
in Figure \ref{A}.
\end{definition}

\FRAME{ftbphFU}{6.5561in}{3.7066in}{0pt}{\Qcb{Reporter Model A}}{\Qlb{A}}{%
reporting_network.jpg}{\special{language "Scientific Word";type
"GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file "F";width
6.5561in;height 3.7066in;depth 0pt;original-width 9.0183in;original-height
5.0816in;cropleft "0";croptop "1";cropright "1";cropbottom "0";filename
'../Images/reporting_network.jpg';file-properties "XNPEU";}}

The deterministic variable $o_{i,j,t}$ accurately models the actual decision
to report that each observer must make, but it also presents certain
inference challenges, as we will discuss later. This model makes some strict
assumptions we should review. The uniform priors for the observer parameters
and the topic bias are uninformative, and represent a first investigation.
More informative distributions might be available in certain circumstances.
We also note that the problem of infering $\beta _{i,j}$ becomes more
difficult if $\left\vert \delta _{j}-\frac{1}{2}\right\vert $ grows too
small, since the $f_{j,t}$ input will become indistinguishable from the
random noise $r_{i,j,t}$.

We are interested first in the quality of $b_{j,t}$ as an estimator for $%
f_{j,t}$. Second, we wish to recover or at least bound the awareness biases $%
\beta _{i,j}$ so we may downweight or ignore unaware observers in the
future. The task of infering $\varepsilon _{i,j}$ is of minimal interest but
happens to be particularly simple.

One of the principal advantages to this model is that it breaks easily into
independent subgraphs. For example, all variables associated with each topic 
$j$ are independent of all other topic's variables, so we may perform
inference within each topic network separately.

\section{Parameter Estimation Via Particle Methods in PyMC3}

Before we make any subtle approach at parameter recovery, we consider how
well a blunt particle-based parameter estimation method can do. Using PyMC3,
we use the No U-Turns Sampler (NUTS), a Hamiltonian Monte Carlo approach to
estimate $\varepsilon _{i,j},\beta _{i,j}$ and $\delta _{j}$, while applying
the Binary Gibbs Metropolis Sampler (BGMS) to recover $f_{j,t},\alpha
_{i,j,t},$ and $\tau _{i,j,t}$. The details are shown in Appendix C. For
this experiment, we set the number of observers to $n_{i}=20$, the number of
timesteps to $n_{t}=100$, and restrict our review to a single topic, $%
n_{j}=1 $. We ran 1000 samples, with 1000 burn-in (tuning) time steps, which
took roughly 1.5 hours on a 4-core Linux machine. The results are summarized
in Figure \ref{PYMC3}\ below.

\FRAME{ftbphFU}{5.546in}{3.7066in}{0pt}{\Qcb{The results of the PyMC3
experiment recovering parameters for Model A. The plots on the left show the
empirical densities as histograms, and the plots on the right show values
sampled. }}{\Qlb{PYMC3}}{pymc3results.jpg}{\special{language "Scientific
Word";type "GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file
"F";width 5.546in;height 3.7066in;depth 0pt;original-width
12.0001in;original-height 8.0004in;cropleft "0";croptop "1";cropright
"1";cropbottom "0";filename '../Images/pymc3results.jpg';file-properties
"XNPEU";}}These estimations for $f_{j,t}$ are 98\% accurate, but the
estimates for delta are poor (a mean of $\hat{\delta}=0.44$ compared to $%
\delta =0.35$). Importantly, the estimates for $\hat{\beta}_{i,j}$ performed
fairly well. The mean $\hat{\beta}_{i,j}$ values and true $\beta _{i,j}$ are
shown in Figure \ref{betahat}.

\FRAME{ftbpFU}{6.0597in}{4.0491in}{0pt}{\Qcb{Comparison of the mean $\hat{%
\protect\beta}$ values to the true $\protect\beta $ values over observers $i$%
, from the PyMC3 experimental results.}}{\Qlb{betahat}}{betahat.jpg}{\special%
{language "Scientific Word";type "GRAPHIC";maintain-aspect-ratio
TRUE;display "USEDEF";valid_file "F";width 6.0597in;height 4.0491in;depth
0pt;original-width 6.0001in;original-height 3.9998in;cropleft "0";croptop
"1";cropright "1";cropbottom "0";filename
'../Images/betahat.jpg';file-properties "XNPEU";}}This particle-based
approach represents a baseline for the approximate inference that does not
take advantage of the details of the model, and we will see that we can
improve upon it.

\section{Improved Estimators}

Let's consider how we could approximate $\beta _{i,j}$ using the assumed
distributions. We will begin by simplifying our view of the model
incrementally. First, we consider only a single topic's information network,
as shown in Figure \ref{rj}. \FRAME{ftbphFU}{6.704in}{3.7048in}{0pt}{\Qcb{%
Reporter Model A shown for a single topic $j$.}}{\Qlb{rj}}{%
reporting_network_j.jpg}{\special{language "Scientific Word";type
"GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file "F";width
6.704in;height 3.7048in;depth 0pt;original-width 8.9404in;original-height
4.9242in;cropleft "0";croptop "1";cropright "1";cropbottom "0";filename
'../Images/reporting_network_j.jpg';file-properties "XNPEU";}}Next we reduce
consider only the contributions of a single observer $\bar{\imath}$, shown
in Figure \ref{rij}. 

\FRAME{ftbphFU}{6.6443in}{3.7048in}{0pt}{\Qcb{Reporter Model A reduced to a
single observer and single topic.}}{\Qlb{rij}}{reporting_network_ji.jpg}{%
\special{language "Scientific Word";type "GRAPHIC";maintain-aspect-ratio
TRUE;display "USEDEF";valid_file "F";width 6.6443in;height 3.7048in;depth
0pt;original-width 8.86in;original-height 4.9242in;cropleft "0";croptop
"1";cropright "1";cropbottom "0";filename
'../Images/reporting_network_ji.jpg';file-properties "XNPEU";}}

Finally, we recognize that under these conditions it is easy to filter out
the "no report" observations. If we condition on $\tau _{t}=1$ we restrict
ourselves to a review of the informative reports from this observer, i.e.~%
\begin{equation*}
\{o_{t}:o_{t}\neq 2\},
\end{equation*}%
and we can write 
\begin{equation*}
o_{t}=\alpha _{t}f_{t}+\left( 1-\alpha _{t}\right) r_{t}.
\end{equation*}%
This simplification is shown in Figure \ref{ijtau}. \FRAME{ftbphFU}{6.6443in%
}{3.7048in}{0pt}{\Qcb{The Reporter Model A simplified to a single topic and
user, with no-report observations removed.}}{\Qlb{ijtau}}{%
reporting_network_ijtau.jpg}{\special{language "Scientific Word";type
"GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file "F";width
6.6443in;height 3.7048in;depth 0pt;original-width 8.86in;original-height
4.9242in;cropleft "0";croptop "1";cropright "1";cropbottom "0";filename
'../Images/reporting_network_ijtau.jpg';file-properties "XNPEU";}}

We may comprehensively describe the probability distribution for $o_{t}$
under these conditions using a probability table since this depends only on
binary variables. We recall that the parameter of each Bernoulli random
variable represents the probability that variable equals one. 

%TCIMACRO{\TeXButton{B}{\begin{table}[tbp] \centering}}%
%BeginExpansion
\begin{table}[tbp] \centering%
%EndExpansion
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
$o_{t}$ & $\alpha _{t}$ & $f_{t}$ & $r_{t}$ & $P\left( \alpha _{t}\right) $
& $P\left( f_{t}\right) $ & $P\left( r_{t}\right) $ \\ \hline
$0$ & $1$ & $0$ & $0$ & $\beta $ & $1-\delta $ & $0.5$ \\ \hline
$1$ & $1$ & $1$ & $0$ & $\beta $ & $\delta $ & $0.5$ \\ \hline
$1$ & $1$ & $1$ & $1$ & $\beta $ & $\delta $ & $0.5$ \\ \hline
$0$ & $1$ & $0$ & $1$ & $\beta $ & $1-\delta $ & $0.5$ \\ \hline
$1$ & $0$ & $1$ & $1$ & $1-\beta $ & $\delta $ & $0.5$ \\ \hline
$1$ & $0$ & $0$ & $1$ & $1-\beta $ & $1-\delta $ & $0.5$ \\ \hline
$0$ & $0$ & $1$ & $0$ & $1-\beta $ & $\delta $ & $0.5$ \\ \hline
$0$ & $0$ & $0$ & $0$ & $1-\beta $ & $1-\delta $ & $0.5$ \\ \hline
\end{tabular}%
\caption{Truth table for computing $o_t$}\label{TableKey}%
%TCIMACRO{\TeXButton{E}{\end{table}}}%
%BeginExpansion
\end{table}%
%EndExpansion

Each of $\beta ,\delta ,$ and $r_{t}$ are mutually independent variables, so
their joint probability is the product of their marginal probabilities. By
summing up the joint probabilities of combinations that lead us to $o_{t}=1$
we have%
\begin{eqnarray*}
P(o_{t}=1) &=&0.5(\beta _{j}\delta +\delta -\beta \delta +1-\beta
_{t}-\delta +\beta _{t}\delta +\beta _{t}\delta ) \\
&=&0.5(-\beta _{t}+\beta _{t}\delta +1)
\end{eqnarray*}

We would reach the same result with much less work using conditional
probabilities (factors), since%
\begin{eqnarray*}
P(o_{\bar{\imath},j,t}=1) &=&P(o_{\bar{\imath},j,t}=1\mid a_{\bar{\imath}%
,j,t}=0)P(a_{\bar{\imath},j,t}=0)+P(o_{\bar{\imath},j,t}=1\mid a_{\bar{\imath%
},j,t}=1)P(a_{\bar{\imath},j,t}=1) \\
&=&0.5(1-\beta _{\bar{\imath},j})+\delta _{j}\beta _{\bar{\imath},j}.
\end{eqnarray*}

Solving for $\beta$ gives us 
\begin{equation*}
\beta_{\bar{i},j,t} = \frac{2P(o_{\bar{i},j,t}=1) - 1}{2\delta_j - 1}.
\end{equation*}

We approximate 
\begin{equation*}
\delta _{j}\approx \hat{\delta _{j}}=\frac{\#\{o_{i,j,t}:o_{i,j,t}=1\}}{%
\#\{o_{i,j,t}:o_{i,j,t}\neq 2\}},
\end{equation*}

using the sample mean of the informative observations to approximate the
probability that a generated fact equals $1$ (an extension of the
approximation $b_{j,t}=\hat{f}_{j,t}\approx f_{j,t}$). If we have computed $%
b_{j,t}$, however, we already have the observed mean 
\begin{equation*}
\hat{\delta _{j}}=\bar{b_{j,t}},
\end{equation*}%
which immediately fills that role.

Our statistic for $P(o_{\bar{i},j,t}=1)$ is the observed probability 
\begin{equation*}
P(o_{\bar{i},j,t}=1) = \frac{ \# \{o_{\bar{i},j,t} : o_{\bar{i},j,t}=1\}}{
\# \{o_{\bar{i},j,t} : o_{\bar{i},j,t}\neq 2 \} }.
\end{equation*}

Now we can make the approximation%
\begin{eqnarray*}
\beta _{i,j}\approx \hat{\beta _{i,j}} &=&\frac{2\frac{\#\{o_{\bar{\imath}%
,j,t}:o_{\bar{\imath},j,t}=1\}}{\#\{o_{\bar{\imath},j,t}:o_{\bar{\imath}%
,j,t}\neq 2\}}-1}{2\hat{\delta _{j}}-1} \\
&=&\frac{2\frac{\#\{o_{\bar{\imath},j,t}:o_{\bar{\imath},j,t}=1\}}{\#\{o_{%
\bar{\imath},j,t}:o_{\bar{\imath},j,t}\neq 2\}}-1}{2\frac{%
\#\{o_{i,j,t}:o_{i,j,t}=1\}}{\#\{o_{i,j,t}:o_{i,j,t}\neq 2\}}-1}.
\end{eqnarray*}

We note that $\varepsilon _{\bar{\imath},j}$ is best estimated using its
Maximum Likelihood Estimator (MLE),%
\begin{equation*}
\varepsilon _{\bar{\imath},j}\approx \hat{\varepsilon}_{\bar{\imath},j}=%
\frac{\#\{o_{\bar{\imath},j,t}:o_{\bar{\imath},j,t}\neq 2\}}{\#\{o_{\bar{%
\imath},j,t}\}}.
\end{equation*}

In Appendix B we show experimentally that these estimators present a much
less computationally intensive and more accurate method for approximate
parameter estimation, and provide a thorough implementation in Python.

\section{Reducing Untrusted Influence}

We will now consider and review several methods for reducing the influence
of untrustworthy observers in Reporter Model A. These fall into two
categories: \emph{pruning}, which entirely eliminates an observer's
contributions to the fact approximation for a given topic, and its
generalization \emph{reduction}, which decreases our trust level in that
observer's contributions, reducing the influence of their vote. 

These two approaches highlight the two-fold purpose of the trust concept in
our model. We primarily wish to eliminate untrustworthy information streams
to optimize the quality of information we process. However, and possibly
more importantly, we wish to reduce the overhead cost of approximating each
fact in each topic, so we wish to reduce the number of observers whose
reports we consider. In some applications, pruning should be even more
aggressive, removing even nodes that report facts reliably once erroneous
reporters are all removed. We note that in Reporter Model A we do not remove
an observer from all topics if they are unreliable in the sense of a single
topic. In some settings (such as combatting disinformation) it may be
appropriate to prune observers completely from the model for poor
performance in a subset of topics. It may also be appropriate in some
circumstances to inversely weight some observer votes, e.g. in a case where
an observer always reports the opposite of the truth they observe.

Each of the following methods is implemented and explored in Appendix B.

\subsection{Pruning Methods}

The simplest form of pruning we consider is to pause after every $n_{p}$
time steps and construct the approximation $\hat{\beta}_{i,j,t=n_{p}}$ for
each observer $i$ which has not yet been pruned. If this approximation falls
below some threshold $\aleph $ around $0.5$, i.e.%
\begin{equation*}
\hat{\beta}_{i,j,t=n_{p}}\leq \aleph 
\end{equation*}%
we prune observer $i$, and do not include any contributions from this
observer for this topic in future. This method is extremely efficient and in
our experiments produced acceptable results.

We may wish instead to prune only when we are certain that the estimate $%
\hat{\beta}_{i,j,t}$ has converged. We do so naively by checking if the
absolute relative change has dropped below a threshold $h\approx 0.1$. If 
\begin{equation*}
\left\vert \frac{\hat{\beta}_{i,j,t}-\hat{\beta}_{i,j,t-1}}{\hat{\beta}%
_{i,j,t-1}}\right\vert \leq h\text{ AND }\hat{\beta}_{i,j,t}\leq \aleph 
\end{equation*}%
both hold, we mark the observer $i$ as pruned. This is slow in practice if
we compute $\hat{\beta}_{i,j,t}$ at every time step $t$, but produces clean
results. It also gives us a sense of "how"\ untrustworthy an observer was,
since we have a clear sense of when they were pruned: earlier pruning
represents more egregiously low awareness.

\subsection{Markovian Reduction}

We will now consider simple approach to reduction that requires minimal
memory. We start by choosing a reduction constant $\rho \approx 0.95$. We
begin the algorithm at $t=0$ with a weight of $1$ for all observers. At each
timestep $t$ we compute the weighted vote of all observers, and mark all
observers who disagreed with this consensus. We multiply the weights of all
incorrect observers by $\rho $, and continue to timestep $t+1$. The result
is that consistently poor performers lose their influence over the group
vote over time.

In our formulation of Reporter Model A we defined the $\beta $ priors to be
static, so there is no reason to think that later errors are more severe
than earlier errors. However, in real life situations, it is reasonable to
expect that observers would become more aware over time, so later errors
would deserve higher distrust penalties. It also is reasonable to expect
high-priority topics to induce higher awareness levels in observers. In
these settings it might make sense to make $\rho $ a function of time and
topic.

\section{Toward a Better Pruning Stopping Criterion}

\section{Alternate Formulations and Future Work}

\section{Conclusion}

\newpage

\bibliographystyle{amsplain}
\bibliography{acompat,JHU}

\newpage

%TCIMACRO{%
%\TeXButton{appendix}{\section*{Appendix A. Supplemental Derivations}
%}}%
%BeginExpansion
\section*{Appendix A. Supplemental Derivations}
%
%EndExpansion

In the following pages we will reproduce the Python code used to perform the
analysis described. This consists of

\end{document}
