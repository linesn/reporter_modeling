
\documentclass{amsart}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsfonts}
\usepackage{color}
\usepackage[pdftex]{hyperref}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=BibTeX}
%TCIDATA{Created=Thursday, May 12, 2022 21:29:02}
%TCIDATA{LastRevised=Friday, May 13, 2022 19:17:26}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Articles\SW\AMS Journal Article">}
%TCIDATA{Language=American English}
%TCIDATA{CSTFile=amsartci.cst}

\newtheorem{theorem}{Theorem}
\theoremstyle{plain}
\newtheorem{acknowledgement}{Acknowledgement}
\newtheorem{algorithm}{Algorithm}
\newtheorem{axiom}{Axiom}
\newtheorem{case}{Case}
\newtheorem{claim}{Claim}
\newtheorem{conclusion}{Conclusion}
\newtheorem{condition}{Condition}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{criterion}{Criterion}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{exercise}{Exercise}
\newtheorem{lemma}{Lemma}
\newtheorem{notation}{Notation}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{solution}{Solution}
\newtheorem{summary}{Summary}
\numberwithin{equation}{section}
\input{tcilatex}

\begin{document}
\title[News Reporting]{A Bayesian Model for News Reporting}
\author{Nicholas A. Lines}
\address{}
\email[N. Lines]{nicholasalines@gmail.com}
\urladdr{https://github.com/linesn/reporter\_modeling}
\thanks{The author would like to thank Dr. Woolf for advising this project,
as well as the author's friend Rod Gomez for his advice regarding PyMC3.}
\date{May 12, 2022}
\thanks{This paper is part of the author's final project for
EN.625.692.81.SP22 Probabilistic Graphical Models, for Johns Hopkins
University.}

\begin{abstract}
Learning information through unreliable observers is difficult. In news
creation and consumption we encounter problems of this sort, in which
information from various observers of differing awareness levels must be
fused and processed. We introduce a model for news-related information
digestion and consider several methods for weighting or eliminating sources
by credibility levels. We implement this in Python and compare PyMC3's
approximate parameter inference results with tailored estimators, and
discuss variations of this model.
\end{abstract}

\maketitle
\tableofcontents
\listoffigures

\newpage

\section{Modeling Information Collation and Reporting}

Anyone with a social media account and internet connection can expect to be
bombarded by information, opinions, and news. On an individual level,
accumulating important news information is overwhelmingly done through
passive online activities. Five years ago the Pew Research Center found that
67\% of Americans learned about news on social media, and this year they
added that 23\% got their news from podcasts \cite{gottfried2019news}\cite%
{walker2022nearly}. Interestingly, this movement toward digitally-fed news
has also brought on increased concern about legitimacy: Pew also asked their
2021 respondents if they would support Federal internet censorship, and 48\%
said yes, compared with 39\% in 2018. How to use existing systems to find
credible information is a vital question each individual must answer. More
generally, any actor involved in distilling news data into factual reports
must perform a similar credibility analysis using a network of dubious
sources. Self-filtering news data is a difficult challenge, involving both
bias in the sources consulted, bias introduced by those sources, and bias in
credibility assessment introduced by the actor.

In this paper we propose a probabilistic graphical framework with which we
can explore information fusion tasks. This proposed approach is elementary,
but it has the potential to develop as a tool to compliment human
credibility assessment of news information sources. We note that the goal of
our investigation is to improve in recognition of net credibility of sources
in terms of \emph{consensus}, not \emph{truth}. We will model a general
information fusion task and demonstrate several approaches for reducing
input from untrusted sources, and discuss variations of this problem and its
applications.

\section{Related Work}

In recent years, efforts to understand how news information propagates in a
network have largely focused on social networks. In \cite%
{zafarani2015evaluation} we find this problem approached in a way that
explicitly admits that ground truth is unavailable, which inspired our
consensus-based approach. In many applications, including digestion of news
information, ground truth is unavailable, and consensus of a class of
observers or experts is considered its best approximation. Consensus-based
modeling of one kind or other fills an increasingly important role in
medical research and practice \cite{fink1984consensus}, blockchain protocols 
\cite{sankar2017survey}, and other multi-agent systems \cite{ren2005survey}.

Social media analysis frequently turns to consensus-based approaches with
success. This is evident in applications such as trust exploration \cite%
{heuer2018trust}, and efforts to characterize social dynamics to gauge
adoption of new technology, like in \cite{kohler2001density}. We emphasize
that consensus-based approaches have great potential for misinterpretation
and abuse in social (particularly news analysis)\ settings. Discarding
disagreements from consensus in these settings may ignore early warnings,
marginalized social groups, or expert opinions, and may obscure the true
evolution of opinion. We urge that these methods be applied with caution and
intentionally used to filter noise under careful supervision.

Analysis of how credibility is changed within a network of communicating
agents is often connected to the concept of belief propagation, a term used
both for the idea in general of spreading beliefs, but also specifically
applied to the sum-product algorithm for this purpose pioneered by Judea
Pearl. A useful survey on this subject is provided in \cite%
{yedidia2003understanding}.

Storing and using knowledge in a probabilistic graphical framework is
usually the realm of knowledge graphs. For a fairly thorough source that
introduces knowledge graphs and their applications, we refer to \cite%
{hogan2021knowledge}. Another name this problem falls under is "information
fusion," which has begun to be applied to text-based problems as well (see 
\cite{levchuk2015probabilistic} and \cite{radev2000common}).

\section{A Bayesian Network Model}

To motivate our model and the related inference problems, we will consider
the following common situation. A news analyst is tasked with understanding
and summarizing news over time, covering several news topics. This analyst
is disconnected from the actual chain of events of interest, and relies
entirely on a set of first-hand observers to pass on reports about these
topics. However, not all observers are alike. Some are more apt to report
information than others. Some are more aware of a particular news topic than
others. We will make the (significant) assumption that a consensus of
observers represents accepted fact for the analyst. The analyst's principal
task is to identify observations held in consensus and report these.
Secondarily, the analyst wishes to "weed out" observations that are
unhelpful. If an observer consistently disagrees with the general consensus
on a topic, that observer does not need to be surveyed on that topic, or
perhaps their response should be weighted low, proportionate in some way to
the trust they have accrued.

We will now introduce a Bayesian network that generatively models this
situation with certain constraints. In particular we will only consider
binary facts related to each topic.

\begin{definition}
\label{d1}\textbf{Reporter Model A}: Let $n_{j}$ be the number of news
topics of interest, $n_{i}$ the number of observers, and $n_{t}$ the number
of timesteps in the modeled timeframe. For each topic $j=1,\dots ,n_{j}$ we
assume that news topic has a bias 
\begin{equation*}
\delta _{j}\sim ~Uniform\left( 0,1\right) 
\end{equation*}%
that indicates preference toward a fact value of $1$. At each time step $%
t=1,\dots ,n_{t}$ a new fact is generated%
\begin{equation*}
f_{j,t}\sim ~Bernoulli\left( \delta _{j}\right) .
\end{equation*}%
Each observer $i=1,\dots ,n_{i}$ has a bias that indicates how willing they
are to report their observations about this topic,%
\begin{equation*}
\varepsilon _{i,j}\sim ~Uniform\left( 0,1\right) ,
\end{equation*}%
and an awareness level for this topic,%
\begin{equation*}
\beta _{i,j}\sim ~Uniform\left( 0,1\right) .
\end{equation*}%
At each timestep they draw a decision about whether to report%
\begin{equation*}
\tau _{i,j,t}\sim ~Bernoulli\left( \varepsilon _{i,j}\right) 
\end{equation*}%
and draw to decide if they are aware of the current fact%
\begin{equation*}
\alpha _{i,j,t}\sim ~Bernoulli\left( \beta _{i,j}\right) .
\end{equation*}%
We also generate random noise 
\begin{equation*}
r_{i,j,t}\sim ~Bernoulli\left( \frac{1}{2}\right) .
\end{equation*}%
The observer then computes%
\begin{equation*}
o_{i,j,t}=\tau _{i,j,t}\left( \alpha _{i,j,t}f_{j,t}+\left( 1-\alpha
_{i,j,t}r_{i,j,t}\right) \right) +2\left( 1-\tau _{i,j,t}\right) 
\end{equation*}%
which is their observation passed on to the analyst. This means that if the
observer is aware and willing to report, they pass on the true fact. If they
are aware but unwilling to report, they pass on the value $2$, which means
nothing was reported. If they are willing to report but unaware of the fact,
they report the random noise.

The analyst at each time step computes the vote $b_{j,t}=\limfunc{mode}%
\left( \left\{ o_{i,j,t}:o_{i,j,t}\neq 2\right\} \right) $, which represents
the consensus for fact $f_{j,t}$. This model is presented as a plate diagram
in Figure \ref{A}.
\end{definition}

\FRAME{ftbphFU}{6.5561in}{3.7066in}{0pt}{\Qcb{Reporter Model A}}{\Qlb{A}}{%
reporting_network.jpg}{\special{language "Scientific Word";type
"GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file "F";width
6.5561in;height 3.7066in;depth 0pt;original-width 9.0183in;original-height
5.0816in;cropleft "0";croptop "1";cropright "1";cropbottom "0";filename
'../Images/reporting_network.jpg';file-properties "XNPEU";}}

The deterministic variable $o_{i,j,t}$ accurately models the actual decision
to report that each observer must make, but it also presents certain
inference challenges, as we will discuss later. This model makes some strict
assumptions we should review. The uniform priors for the observer parameters
and the topic bias are uninformative, and represent a first investigation.
More informative distributions might be available in certain circumstances.
We also note that the problem of inferring $\beta _{i,j}$ becomes more
difficult if $\left\vert \delta _{j}-\frac{1}{2}\right\vert $ grows too
small, since the $f_{j,t}$ input will become indistinguishable from the
random noise $r_{i,j,t}$.

We are interested first in the quality of $b_{j,t}$ as an estimator for $%
f_{j,t}$. Second, we wish to recover or at least bound the awareness biases $%
\beta _{i,j}$ so we may downweight or ignore unaware observers in the
future. The task of inferring $\varepsilon _{i,j}$ is of minimal interest
but happens to be particularly simple.

One of the principal advantages to this model is that it breaks easily into
independent subgraphs. For example, all variables associated with each topic 
$j$ are independent of all other topic's variables, so we may perform
inference within each topic network separately.

\section{Parameter Estimation Via Particle Methods in PyMC3}

Before we make any subtle approach at parameter recovery, we consider how
well a blunt particle-based parameter estimation method can do. Using PyMC3,
we apply the No U-Turns Sampler (NUTS), a Hamiltonian Monte Carlo approach
to estimate $\varepsilon _{i,j},\beta _{i,j}$ and $\delta _{j}$, while
utilizing the Binary Gibbs Metropolis Sampler (BGMS) to recover $%
f_{j,t},\alpha _{i,j,t},$ and $\tau _{i,j,t}$. The details are shown in
Appendix C. For this experiment, we set the number of observers to $n_{i}=20$%
, the number of timesteps to $n_{t}=100$, and restrict our review to a
single topic, $n_{j}=1$. We ran 1000 samples, with 1000 burn-in (tuning)
time steps, which took roughly 1.5 hours on a 4-core Linux machine. The
results are summarized in Figure \ref{PYMC3}\ below.

\FRAME{ftbphFU}{5.546in}{3.7066in}{0pt}{\Qcb{The results of the PyMC3
experiment recovering parameters for Model A. The plots on the left show the
empirical densities as histograms, and the plots on the right show values
sampled. }}{\Qlb{PYMC3}}{pymc3results.jpg}{\special{language "Scientific
Word";type "GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file
"F";width 5.546in;height 3.7066in;depth 0pt;original-width
12.0001in;original-height 8.0004in;cropleft "0";croptop "1";cropright
"1";cropbottom "0";filename '../Images/pymc3results.jpg';file-properties
"XNPEU";}}These estimations for $f_{j,t}$ are 98\% accurate, but the
estimates for delta are poor (a mean of $\hat{\delta}=0.44$ compared to $%
\delta =0.35$). Importantly, the estimates for $\hat{\beta}_{i,j}$ performed
fairly well. The mean $\hat{\beta}_{i,j}$ values and true $\beta _{i,j}$ are
shown in Figure \ref{betahat}.

\FRAME{ftbpFU}{6.0597in}{4.0491in}{0pt}{\Qcb{Comparison of the mean $\hat{%
\protect\beta}$ values to the true $\protect\beta $ values over observers $i$%
, from the PyMC3 experimental results.}}{\Qlb{betahat}}{betahat.jpg}{\special%
{language "Scientific Word";type "GRAPHIC";maintain-aspect-ratio
TRUE;display "USEDEF";valid_file "F";width 6.0597in;height 4.0491in;depth
0pt;original-width 6.0001in;original-height 3.9998in;cropleft "0";croptop
"1";cropright "1";cropbottom "0";filename
'../Images/betahat.jpg';file-properties "XNPEU";}}This particle-based
approach represents a baseline for approximate inference that does not take
advantage of the details of the model, and we will see that we can improve
upon it.

An interesting limitation of PyMC3 is shown in this demonstration: it cannot
model observations from deterministic variables. In our case $o_{i,j,t}$ is
deterministic in that it is entirely determined as a logical combination of
stochastic variables. PyMC3 cannot sample from this, so an unattractive
stopgap is commonly used in such cases. We define a new random variable 
\begin{equation*}
X_{i,j,t}\sim ~Normal\left( \mu =o_{i,j,t},\sigma =0.01\right) ,
\end{equation*}%
which we can sample from. This introduces minimal variance, and overcomes
the obstacle.

\section{Improved Estimators}

Let's consider how we could approximate $\beta _{i,j}$ using the assumed
distributions. We will begin by simplifying our view of the model
incrementally. First, we consider only a single topic's information network,
as shown in Figure \ref{rj}. \FRAME{ftbphFU}{6.704in}{3.7048in}{0pt}{\Qcb{%
Reporter Model A shown for a single topic $j$.}}{\Qlb{rj}}{%
reporting_network_j.jpg}{\special{language "Scientific Word";type
"GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file "F";width
6.704in;height 3.7048in;depth 0pt;original-width 8.9404in;original-height
4.9242in;cropleft "0";croptop "1";cropright "1";cropbottom "0";filename
'../Images/reporting_network_j.jpg';file-properties "XNPEU";}}Next we
consider only the contributions of a single observer $\bar{\imath}$, shown
in Figure \ref{rij}. 

\FRAME{ftbphFU}{6.6443in}{3.7048in}{0pt}{\Qcb{Reporter Model A reduced to a
single observer and single topic.}}{\Qlb{rij}}{reporting_network_ji.jpg}{%
\special{language "Scientific Word";type "GRAPHIC";maintain-aspect-ratio
TRUE;display "USEDEF";valid_file "F";width 6.6443in;height 3.7048in;depth
0pt;original-width 8.86in;original-height 4.9242in;cropleft "0";croptop
"1";cropright "1";cropbottom "0";filename
'../Images/reporting_network_ji.jpg';file-properties "XNPEU";}}

Finally, we recognize that under these conditions it is easy to filter out
the "no report" observations. If we condition on $\tau _{t}=1$ we restrict
ourselves to a review of the informative reports from this observer, i.e.~%
\begin{equation*}
\{o_{t}:o_{t}\neq 2\},
\end{equation*}%
and we can write 
\begin{equation*}
o_{t}=\alpha _{t}f_{t}+\left( 1-\alpha _{t}\right) r_{t}.
\end{equation*}%
This simplification is shown in Figure \ref{ijtau}. \FRAME{ftbphFU}{6.6443in%
}{3.7048in}{0pt}{\Qcb{The Reporter Model A simplified to a single topic and
user, with no-report observations removed.}}{\Qlb{ijtau}}{%
reporting_network_ijtau.jpg}{\special{language "Scientific Word";type
"GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file "F";width
6.6443in;height 3.7048in;depth 0pt;original-width 8.86in;original-height
4.9242in;cropleft "0";croptop "1";cropright "1";cropbottom "0";filename
'../Images/reporting_network_ijtau.jpg';file-properties "XNPEU";}}

We may comprehensively describe the probability distribution for $o_{t}$
under these conditions using the probability table, Table \ref{TableKey},
since this depends only on binary variables. We recall that the parameter of
each Bernoulli random variable represents the probability that variable
equals one. 

%TCIMACRO{\TeXButton{B}{\begin{table}[tbp] \centering}}%
%BeginExpansion
\begin{table}[tbp] \centering%
%EndExpansion
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
$o_{t}$ & $\alpha _{t}$ & $f_{t}$ & $r_{t}$ & $P\left( \alpha _{t}\right) $
& $P\left( f_{t}\right) $ & $P\left( r_{t}\right) $ \\ \hline
$0$ & $1$ & $0$ & $0$ & $\beta $ & $1-\delta $ & $0.5$ \\ \hline
$1$ & $1$ & $1$ & $0$ & $\beta $ & $\delta $ & $0.5$ \\ \hline
$1$ & $1$ & $1$ & $1$ & $\beta $ & $\delta $ & $0.5$ \\ \hline
$0$ & $1$ & $0$ & $1$ & $\beta $ & $1-\delta $ & $0.5$ \\ \hline
$1$ & $0$ & $1$ & $1$ & $1-\beta $ & $\delta $ & $0.5$ \\ \hline
$1$ & $0$ & $0$ & $1$ & $1-\beta $ & $1-\delta $ & $0.5$ \\ \hline
$0$ & $0$ & $1$ & $0$ & $1-\beta $ & $\delta $ & $0.5$ \\ \hline
$0$ & $0$ & $0$ & $0$ & $1-\beta $ & $1-\delta $ & $0.5$ \\ \hline
\end{tabular}%
\caption{Truth table for computing $o_t$}\label{TableKey}%
%TCIMACRO{\TeXButton{E}{\end{table}}}%
%BeginExpansion
\end{table}%
%EndExpansion

Each of $\beta ,\delta ,$ and $r_{t}$ are mutually independent variables, so
their joint probability is the product of their marginal probabilities. By
summing up the joint probabilities of combinations that lead us to $o_{t}=1$
we have%
\begin{eqnarray*}
P(o_{t}=1) &=&0.5(\beta _{j}\delta +\delta -\beta \delta +1-\beta
_{t}-\delta +\beta _{t}\delta +\beta _{t}\delta ) \\
&=&0.5(-\beta _{t}+\beta _{t}\delta +1)
\end{eqnarray*}

We would reach the same result with much less work using conditional
probabilities (factors), since%
\begin{eqnarray*}
P(o_{\bar{\imath},j,t}=1) &=&P(o_{\bar{\imath},j,t}=1\mid a_{\bar{\imath}%
,j,t}=0)P(a_{\bar{\imath},j,t}=0)+P(o_{\bar{\imath},j,t}=1\mid a_{\bar{\imath%
},j,t}=1)P(a_{\bar{\imath},j,t}=1) \\
&=&0.5(1-\beta _{\bar{\imath},j})+\delta _{j}\beta _{\bar{\imath},j}.
\end{eqnarray*}

Solving for $\beta$ gives us 
\begin{equation*}
\beta_{\bar{i},j,t} = \frac{2P(o_{\bar{i},j,t}=1) - 1}{2\delta_j - 1}.
\end{equation*}

We approximate 
\begin{equation*}
\delta _{j}\approx \hat{\delta _{j}}=\frac{\#\{o_{i,j,t}:o_{i,j,t}=1\}}{%
\#\{o_{i,j,t}:o_{i,j,t}\neq 2\}},
\end{equation*}

using the sample mean of the informative observations to approximate the
probability that a generated fact equals $1$ (an extension of the
approximation $b_{j,t}=\hat{f}_{j,t}\approx f_{j,t}$). If we have computed $%
b_{j,t}$, however, we already have the observed mean 
\begin{equation*}
\hat{\delta _{j}}=\bar{b_{j,t}},
\end{equation*}%
which immediately fills that role.

Our statistic for $P(o_{\bar{i},j,t}=1)$ is the observed probability 
\begin{equation*}
P(o_{\bar{i},j,t}=1) = \frac{ \# \{o_{\bar{i},j,t} : o_{\bar{i},j,t}=1\}}{
\# \{o_{\bar{i},j,t} : o_{\bar{i},j,t}\neq 2 \} }.
\end{equation*}

Now we can make the approximation%
\begin{eqnarray*}
\beta _{i,j}\approx \hat{\beta _{i,j}} &=&\frac{2\frac{\#\{o_{\bar{\imath}%
,j,t}:o_{\bar{\imath},j,t}=1\}}{\#\{o_{\bar{\imath},j,t}:o_{\bar{\imath}%
,j,t}\neq 2\}}-1}{2\hat{\delta _{j}}-1} \\
&=&\frac{2\frac{\#\{o_{\bar{\imath},j,t}:o_{\bar{\imath},j,t}=1\}}{\#\{o_{%
\bar{\imath},j,t}:o_{\bar{\imath},j,t}\neq 2\}}-1}{2\frac{%
\#\{o_{i,j,t}:o_{i,j,t}=1\}}{\#\{o_{i,j,t}:o_{i,j,t}\neq 2\}}-1}.
\end{eqnarray*}

We note that $\varepsilon _{\bar{\imath},j}$ is best estimated using its
Maximum Likelihood Estimator (MLE),%
\begin{equation*}
\varepsilon _{\bar{\imath},j}\approx \hat{\varepsilon}_{\bar{\imath},j}=%
\frac{\#\{o_{\bar{\imath},j,t}:o_{\bar{\imath},j,t}\neq 2\}}{\#\{o_{\bar{%
\imath},j,t}\}}.
\end{equation*}

In Appendix B we show experimentally that these estimators present a much
less computationally intensive and more accurate method for approximate
parameter estimation, and provide a thorough implementation in Python.

\section{Reducing Untrusted Influence}

We will now consider and review several methods for reducing the influence
of untrustworthy observers in Reporter Model A. These fall into two
categories: \emph{pruning}, which entirely eliminates an observer's
contributions to the fact approximation for a given topic, and its
generalization \emph{reduction}, which decreases our trust level in that
observer's contributions, reducing the influence of their vote. 

These two approaches highlight the two-fold purpose of the trust concept in
our model. We primarily wish to eliminate untrustworthy information streams
to optimize the quality of information we process. However, and possibly
more importantly, we wish to reduce the overhead cost of approximating each
fact in each topic, so we wish to reduce the number of observers whose
reports we consider. In some applications, pruning should be even more
aggressive, removing even nodes that report facts reliably once erroneous
reporters are all removed. We note that in Reporter Model A we do not remove
an observer from all topics if they are unreliable in the sense of a single
topic. In some settings (such as combatting disinformation) it may be
appropriate to prune observers completely from the model for poor
performance in a subset of topics. It may also be appropriate in some
circumstances to inversely weight some observer votes, e.g. in a case where
an observer always reports the opposite of the truth they observe.

Each of the following methods is implemented and explored in Appendix B.

\subsection{Pruning Methods}

The simplest form of pruning we consider is to pause after every $n_{p}$
time steps and construct the approximation $\hat{\beta}_{i,j,t=n_{p}}$ for
each observer $i$ which has not yet been pruned. If this approximation falls
below some threshold $\aleph $ around $0.5$, i.e.%
\begin{equation*}
\hat{\beta}_{i,j,t=n_{p}}\leq \aleph 
\end{equation*}%
we prune observer $i$, and do not include any contributions from this
observer for this topic in future. This method is extremely efficient and in
our experiments produced acceptable results.

We may wish instead to prune only when we are certain that the estimate $%
\hat{\beta}_{i,j,t}$ has converged. We do so naively by checking if the
absolute relative change has dropped below a threshold $h\approx 0.1$. If 
\begin{equation*}
\left\vert \frac{\hat{\beta}_{i,j,t}-\hat{\beta}_{i,j,t-1}}{\hat{\beta}%
_{i,j,t-1}}\right\vert \leq h\text{ AND }\hat{\beta}_{i,j,t}\leq \aleph 
\end{equation*}%
hold, we mark the observer $i$ as pruned. This is slow in practice if we
compute $\hat{\beta}_{i,j,t}$ at every time step $t$, but produces clean
results. It also gives us a sense of "how"\ untrustworthy an observer was,
since we have a clear sense of when they were pruned: earlier pruning
represents more egregiously low awareness.

\subsection{Markovian Reduction}

We will now consider a simple approach to reduction that requires minimal
memory. We start by choosing a reduction constant $\rho \approx 0.95$. We
begin the algorithm at $t=0$ with a weight of $1$ for all observers. At each
timestep $t$ we compute the weighted vote of all observers, and mark all
observers who disagreed with this consensus. We multiply the weights of all
incorrect observers by $\rho $, and continue to timestep $t+1$. The result
is that consistently poor performers lose their influence over the group
vote over time.

The parameter $\rho $ is sensitive: if the parameter is too low, it will
result in a single observer emerging as the "most trusted"\ observer, whose
vote is law. If the parameter is too high, the observers will not be
separated as quickly. In future work, we may wish to investigate the
relationship between choices of $\rho ,n_{i},$ and $n_{t}$, to identify
ideal parameter ranges for distinguishing observer awareness.

In our formulation of Reporter Model A we defined the $\beta $ priors to be
static, so there is no reason to think that later errors are more severe
than earlier errors. However, in real life situations, it is reasonable to
expect that observers would become more aware over time, so later errors
would deserve higher distrust penalties. It also is reasonable to expect
high-priority topics to induce higher awareness levels in observers. In
these settings it might make sense to make $\rho $ a function of time and
topic.

\section{Toward a Better Pruning Stopping Criterion}

We previously discussed pruning when the estimate for $\hat{\beta}_{i,j,t}$
converges, but it would perhaps be preferable if we could stop and prune
when $P\left( \beta _{i,j,t}=\hat{\beta}_{i,j,t}\right) $ reaches a
threshold. As we consider this possibility, for brevity we will use the
convention $x^{v}$ to represent the random variable assignment $x=v$ where $v
$ is in the set of possible values of $x$.

Let us return to the simplification where one observer over $n_{t}$ time
steps provides observations, with all the "failed to report"\ data removed.
We can show that the following holds via variable elimination. 

\begin{theorem}
\label{t1}In the simplification of Reporter Model A in which a single
observer provides input for a single topic, the observations for any given
time step $t$ have the following distribution%
\begin{eqnarray*}
P\left( o_{t}^{1}\mid a_{t},f_{t},r_{t},\beta ,\delta \right)  &=&P\left(
o_{t}^{1}\mid \beta ,\delta \right) =\beta \left( \delta -\frac{1}{2}\right)
+\frac{1}{2}, \\
P\left( o_{t}^{0}\mid a_{t},f_{t},r_{t},\beta ,\delta \right)  &=&P\left(
o_{t}^{0}\mid \beta ,\delta \right) =\beta \left( \frac{1}{2}-\delta \right)
+\frac{1}{2}.
\end{eqnarray*}%
Furthermore, $P\left( o_{t}^{1}\right) =P\left( o_{t}^{0}\right) =\frac{1}{2}%
.$
\end{theorem}

This is established by Proof 1 in Appendix A. 

Thus the probability of reporting outcomes is independent of the time step
and all variables contained within that time step. Let 
\begin{equation*}
E=\left\{ o_{t}\right\} _{t=1}^{n_{t}}
\end{equation*}%
be the evidence, the sequence of realizations observed. Let $N_{0}$ and $%
N_{1}$ be the numbers of 0's and 1's observed in this sequence,%
\begin{equation*}
N_{v}=\#\left\{ o_{t}:o_{t}^{v}\right\} _{t=1}^{n_{t}}.
\end{equation*}%
Then Bayes' law gives us

\begin{eqnarray*}
P\left( \beta =\hat{\beta},\delta =\hat{\delta}\mid o_{t}^{1}\right)  &=&%
\frac{P\left( o_{t}^{1}\mid \beta =\hat{\beta},\delta =\hat{\delta}\right)
P\left( \beta =\hat{\beta},\delta =\hat{\delta}\mid E_{t-1}\right) }{P\left(
o_{t}^{1}\right) } \\
&=&\frac{\left( \hat{\beta}\left( \hat{\delta}-\frac{1}{2}\right) +\frac{1}{2%
}\right) P\left( \beta =\hat{\beta},\delta =\hat{\delta}\mid E_{t-1}\right) 
}{0.5} \\
&=&2\left( \hat{\beta}\left( \hat{\delta}-\frac{1}{2}\right) +\frac{1}{2}%
\right) P\left( \beta =\hat{\beta},\delta =\hat{\delta}\mid E_{t-1}\right) .
\end{eqnarray*}%
At time $t=0$ we have the uninformative prior, 
\begin{equation*}
P\left( \beta =\hat{\beta},\delta =\hat{\delta}\mid E_{0}\right) =P\left(
\beta =\hat{\beta}\mid E_{0}\right) P\left( \delta =\hat{\delta}\mid
E_{0}\right) =1.
\end{equation*}%
We can use Bayesian updates at each time step to develop a posterior
distribution for $\beta $ under the condition $\delta =\hat{\delta}_{t}$.
This means that we can halt at time $t$ if $P\left( \beta =\hat{\beta}%
_{t}\mid \delta =\hat{\delta}_{t},E_{t-1}\right) $ stabilizes (in a
Kullback-Leibler sense) and prune this observer if $\hat{\beta}_{t}\leq
\aleph $.

This is computationally expensive compared to our other approaches, and is
not yet implemented in our code.

\section{Alternate Formulations and Future Work}

The Reporter Model A we have described has broad applications, but is not
universally suitable, so it behooves us to consider minor alterations that
fulfill similar needs. One such alteration we encountered early on when
applying Model A is described below. We motivate this model as follows.
Suppose our news analyst is interested in a set of topic states $\left\{
\delta _{j}\right\} _{j=1}^{n_{j}}.$ For example, each may represent the
disaster readiness level of a state in the United States. The observers,
rather than all encountering the same binary fact each timestep, now
encounter individual facts. This might model a situation where each observer
asks yes-or-no-questions of a representative of each state. 

\begin{definition}
\textbf{Reporter Model B:} We define this precisely the same as Reporter
Model A in Definition \ref{d1} except that the facts $f_{i.j.t}$ are now
within the observer loop, meaning they are unique to each observer. This
model is shown in \autoref{B}.
\end{definition}

\FRAME{ftbpFU}{6.5561in}{3.7066in}{0pt}{\Qcb{Reporter Model B}}{\Qlb{B}}{%
reporting_networkb.jpg}{\special{language "Scientific Word";type
"GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file "F";width
6.5561in;height 3.7066in;depth 0pt;original-width 9.0183in;original-height
5.0816in;cropleft "0";croptop "1";cropright "1";cropbottom "0";filename
'../Images/reporting_networkB.jpg';file-properties "XNPEU";}}

In this model, we are no longer interested in the individual facts $f_{i,j,t}
$, but instead wish to recover $\delta _{j}$. This model has several
computational advantages, since it now presents plates (i.e. for-loops)\
that are strictly ordered as subsets. This is advantageous for some
probabilistic languages (including PyMC3).

In our code we have implemented but not exhaustively tested the discussed
reduction strategies. In future work we wish to evaluate these methods more
thoroughly, including probability-based pruning. An element from real-life
which our models do not replicate is the concept of finding new information
sources. Finding new sources to replace less informed observers would be
extremely useful, and could transform this problem into an explore versus
exploit task, much like a multi-armed-bandit problem. 

Finally, the most important difference between our model and real-life
situations we wish to examine is that news is rarely expressed as binary
facts. Applying our work to a real-world situation would require
accomplishing numerous fact-extraction and fact-matching tasks within the
realm of natural language processing. We hope that these models we discussed
are sufficiently portable that such a text-to-fact tool could plug into the
models with minimal structural changes.

\section{Conclusion}

The model(s) proposed in this paper represents only a beginning of this type
of investigation, and we feel optimistic that more efforts in this vein will
follow. The human brain has hitherto been assigned the work of sorting and
prioritizing information sources almost exclusively, but cognitive
thresholds, if they have not yet been exceeded by news volume, soon will be.
In such a setting it will be invaluable for news analysts and news readers
alike to become equipped with tools that triage their media exposure using
credibility assessments and other features of the media and its sources.

\newpage

\bibliographystyle{amsplain}
\bibliography{acompat,JHU}

\newpage

%TCIMACRO{%
%\TeXButton{appendix}{\section*{Appendix A. Supplemental Derivations}}}%
%BeginExpansion
\section*{Appendix A. Supplemental Derivations}%
%EndExpansion

We first provide a proof for \autoref{t1}.

\begin{proof}[Proof 1]
\label{A,1}Recall that we have eliminated observations with value 2 (the "no
report" observations) and are considering one topic and one observer only.
Let $t$ be any given timestep. The random variables $\alpha _{t},f_{t},$ and 
$r_{t}$ are Bernoulli, with the parameters $\beta ,\delta ,$ and $\frac{1}{2}
$. The variable $o$ is produced by computing%
\begin{equation*}
o_{t}=\alpha _{t}f_{t}+\left( 1-\alpha _{t}\right) r_{t},
\end{equation*}%
which yields the following truth table:%
\begin{equation*}
\begin{tabular}{|l|l|l|l|}
\hline
$o_{t}$ & $\alpha _{t}$ & $f_{t}$ & $r_{t}$ \\ \hline
$1$ & $1$ & $1$ & $1$ \\ \hline
$1$ & $1$ & $1$ & $0$ \\ \hline
$1$ & $0$ & $1$ & $1$ \\ \hline
$1$ & $0$ & $0$ & $1$ \\ \hline
$0$ & $1$ & $0$ & $1$ \\ \hline
$0$ & $1$ & $0$ & $0$ \\ \hline
$0$ & $0$ & $1$ & $0$ \\ \hline
$0$ & $0$ & $0$ & $0$ \\ \hline
\end{tabular}%
\end{equation*}%
In this case, the probability of the observer stating the value $1$ is the
sum of the probability of this occurring given all possible immediate parent
variable combinations, 
\begin{eqnarray*}
P\left( o_{t}^{1}\mid \alpha _{t},f_{t},r_{t},\beta ,\delta \right) 
&=&\sum_{i,j,k,l,m}P\left( o_{t}^{1},\alpha
_{t}^{i},f_{t}^{j},r_{t}^{k},\beta ^{l},\delta ^{m}\right)  \\
&=&P\left( o^{1},\alpha ^{1},f^{1},r^{1}\right) +P\left( o^{1},\alpha
^{1},f^{1},r^{0}\right) +P\left( o^{1},\alpha ^{0},f^{1},r^{1}\right)
+P\left( o^{1},\alpha ^{0},f^{0},r^{1}\right)  \\
&=&P\left( o^{1},\alpha ^{1},f^{1}\right) +P\left( o^{1},\alpha
^{0},r^{1}\right)  \\
&=&P\left( o^{1}\mid \alpha ^{1},f^{1}\right) P\left( \alpha
^{1},f^{1}\right) +P\left( o^{1}\mid \alpha ^{0},r^{1}\right) P\left( \alpha
^{0},r^{1}\right) 
\end{eqnarray*}%
Here we may use the independence of the parent variables to simplify,%
\begin{eqnarray*}
P\left( o^{1}\mid \beta ,\delta \right)  &=&P\left( o^{1}\mid \alpha
^{1},f^{1}\right) P\left( \alpha ^{1}\right) P\left( f^{1}\right) +P\left(
o^{1}\mid \alpha ^{0},r^{1}\right) P\left( \alpha ^{0}\right) P\left(
r^{1}\right)  \\
&=&\left( 1\right) \left( \beta \right) \left( \delta \right) +\left(
1\right) \left( 1-\beta \right) \left( \frac{1}{2}\right)  \\
&=&\beta \delta +\frac{1}{2}-\frac{1}{2}\beta  \\
&=&\beta \left( \delta -\frac{1}{2}\right) +\frac{1}{2}.
\end{eqnarray*}%
Similarly we find%
\begin{eqnarray*}
P\left( o^{0}\mid \beta ,\delta \right)  &=&P\left( o^{0}\mid \alpha
^{1},f^{0}\right) P\left( \alpha ^{1}\right) P\left( f^{0}\right) +P\left(
o^{0}\mid \alpha ^{0},r^{0}\right) P\left( \alpha ^{0}\right) P\left(
r^{0}\right)  \\
&=&\left( 1\right) \left( \beta \right) \left( 1-\delta \right) +\left(
1\right) \left( 1-\beta \right) \left( \frac{1}{2}\right)  \\
&=&\beta \left( 1-\delta \right) +\frac{1}{2}-\frac{1}{2}\beta  \\
&=&\beta \left( \frac{1}{2}-\delta \right) +\frac{1}{2}.
\end{eqnarray*}%
Let us consider the marginalization of this probability given the assumption
that $\beta $ and $\delta $ are both uniform random between 0 and 1. This
gives us 
\begin{eqnarray*}
P\left( o^{0}\right)  &=&\int_{l,m}P\left( o^{0}\mid \beta ^{l},\delta
^{m}\right) P\left( \beta ^{l},\delta ^{m}\right) dldm \\
&=&\int_{m}\int_{l}\left( l\left( \frac{1}{2}-m\right) +\frac{1}{2}\right)
P\left( \beta ^{l}\right) P\left( \delta ^{m}\right) dldm \\
&=&\int_{m}\int_{l}\left( l\left( \frac{1}{2}-m\right) +\frac{1}{2}\right)
\left( 1\right) \left( 1\right) dldm \\
&=&\int_{m}\int_{l}\left( l\left( \frac{1}{2}-m\right) +\frac{1}{2}\right)
dldm \\
&=&\int_{0}^{1}\int_{0}^{1}\left( l\left( \frac{1}{2}-m\right) +\frac{1}{2}%
\right) dldm \\
&=&\frac{1}{4}lm\left( l-lm+2\right) |_{l,m=0}^{l,m=1} \\
&=&\frac{1}{2}
\end{eqnarray*}
\end{proof}

It turns out that the awareness variable may be estimated using what we just
proved. We simply compute%
\begin{eqnarray*}
P\left( a^{1}\mid o^{1},\beta ,\delta \right)  &=&\frac{P\left(
a^{1},o^{1}\mid \beta ,\delta \right) }{P\left( o^{1}\mid \beta ,\delta
\right) } \\
&=&\frac{P\left( o^{1}\mid a^{1},\beta ,\delta \right) P\left( a^{1}\mid
\beta ,\delta \right) }{P\left( o^{1}\mid \beta ,\delta \right) } \\
&=&\frac{\left[ P\left( o^{1}\mid a^{1},f^{1},\beta ,\delta \right) +P\left(
o^{1}\mid a^{1},f^{0},\beta ,\delta \right) \right] P\left( a^{1}\mid \beta
\right) }{P\left( o^{1}\mid \beta ,\delta \right) } \\
&=&\frac{\left[ 1+0\right] \beta }{\beta \left( \delta -\frac{1}{2}\right) +%
\frac{1}{2}} \\
&=&\frac{\beta }{\beta \left( \delta -\frac{1}{2}\right) +\frac{1}{2}} \\
&=&\frac{1}{\delta -\frac{1}{2}+\frac{1}{2\beta }}.
\end{eqnarray*}%
And similarly,%
\begin{eqnarray*}
P\left( a^{1}\mid o^{0},\beta ,\delta \right)  &=&\frac{P\left(
a^{1},o^{0}\mid \beta ,\delta \right) }{P\left( o^{0}\mid \beta ,\delta
\right) } \\
&=&\frac{P\left( o^{0}\mid a^{1}\right) P\left( a^{1}\mid \beta ,\delta
\right) }{P\left( o^{0}\right) } \\
&=&\frac{\left[ P\left( o^{0}\mid a^{1},f^{0}\right) +P\left( o^{0}\mid
a^{1},f^{1}\right) \right] P\left( a^{1}\mid \beta \right) }{P\left(
o^{0}\right) } \\
&=&\frac{\left[ 1+0\right] \beta }{\beta \left( \frac{1}{2}-\delta \right) +%
\frac{1}{2}} \\
&=&\frac{\beta }{\beta \left( \frac{1}{2}-\delta \right) +\frac{1}{2}} \\
&=&\frac{1}{\frac{1}{2}-\delta +\frac{1}{2\beta }}
\end{eqnarray*}

This lends itself to an alternative updating scheme. We wish to consider a
Bayesian belief update where we use an observation of $o$ to change our
opinion about the value of $\beta $. We manipulate%
\begin{eqnarray*}
P\left( a^{1}\mid o^{0},\beta ,\delta \right)  &=&\frac{P\left(
a^{1},o^{0}\mid \beta ,\delta \right) }{P\left( o^{0}\mid \beta ,\delta
\right) } \\
\frac{1}{2\beta } &=&\frac{1}{P\left( a^{1}\mid o^{0},\beta ,\delta \right) }%
-\frac{1}{2}+\delta  \\
2\beta  &=&\frac{1}{\frac{1}{P\left( a^{1}\mid o^{0},\beta ,\delta \right) }-%
\frac{1}{2}+\delta } \\
\beta  &=&\frac{1}{2\left( \frac{1}{P\left( a^{1}\mid o^{0},\beta ,\delta
\right) }-\frac{1}{2}+\delta \right) }
\end{eqnarray*}%
We do not know $\delta $, but using a consensus of multiple observers over
multiple draws of $f$ we can approximate it with $\hat{\delta}$. This gives
us the estimator%
\begin{equation*}
\hat{\beta}_{t}=\frac{1}{2\left( \frac{1}{P\left( a^{1}\mid o^{0},\hat{\beta}%
_{t-1},\hat{\delta}_{t-1}\right) }-\frac{1}{2}+\hat{\delta}_{t}\right) }
\end{equation*}%
We can start with a uninformative prior (uniform over $\left[ 0,1\right] $)
and update this via Bayes theorem.

%TCIMACRO{%
%\TeXButton{Appendices}{\addcontentsline{toc}{section}{Appendix B. Code for Reporter Model A}
%\addcontentsline{toc}{section}{Appendix C. Using PyMC3 for Approximate Parameter Estimation in Reporter Model A }}}%
%BeginExpansion
\addcontentsline{toc}{section}{Appendix B. Code for Reporter Model A}
\addcontentsline{toc}{section}{Appendix C. Using PyMC3 for Approximate Parameter Estimation in Reporter Model A }%
%EndExpansion

\end{document}
