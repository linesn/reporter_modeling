
\documentclass{amsart}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsfonts}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=BibTeX}
%TCIDATA{Created=Thursday, February 18, 2021 13:39:50}
%TCIDATA{LastRevised=Saturday, May 07, 2022 23:48:09}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Articles\SW\AMS Journal Article">}
%TCIDATA{Language=American English}
%TCIDATA{CSTFile=amsartci.cst}

\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{solution}{Solution}
\theoremstyle{plain}
\newtheorem{acknowledgement}{Acknowledgement}
\newtheorem{algorithm}{Algorithm}
\newtheorem{axiom}{Axiom}
\newtheorem{case}{Case}
\newtheorem{claim}{Claim}
\newtheorem{conclusion}{Conclusion}
\newtheorem{condition}{Condition}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{criterion}{Criterion}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{exercise}{Exercise}
\newtheorem{lemma}{Lemma}
\newtheorem{notation}{Notation}
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{summary}{Summary}
\numberwithin{equation}{section}
\input{tcilatex}

\begin{document}
\title[Derivations]{EN.625.692.81.SP22 Probabilistic Graphical Models
Project Derivations}
\author{Nicholas Lines}
\email{nicholasalines@gmail.com}
\date{\today }
\maketitle

\section{Simplifying the model}

Suppose we begin with the simpler model given in the following figure. 
\FRAME{dtbpF}{6.6426in}{3.5068in}{0pt}{}{}{simple_reporting_network.jpg}{%
\special{language "Scientific Word";type "GRAPHIC";maintain-aspect-ratio
TRUE;display "USEDEF";valid_file "F";width 6.6426in;height 3.5068in;depth
0pt;original-width 8.2304in;original-height 4.3318in;cropleft "0";croptop
"1";cropright "1";cropbottom "0";filename
'../Images/simple_reporting_network.jpg';file-properties "XNPEU";}}

We have cut out the missing data, and are considering one fact and one
observer only. The random variables $a,f,$ and $r$ are Bernoulli, with the
parameters $\beta ,\delta ,$ and $\frac{1}{2}$. The variable $o$ is produced
by computing%
\begin{equation*}
o=af+\left( 1-a\right) r,
\end{equation*}%
which yields the following truth table:%
\begin{equation*}
\begin{tabular}{llll}
$o$ & $a$ & $f$ & $r$ \\ \hline
$1$ & $1$ & $1$ & $1$ \\ 
$1$ & $1$ & $1$ & $0$ \\ 
$1$ & $0$ & $1$ & $1$ \\ 
$1$ & $0$ & $0$ & $1$ \\ 
$0$ & $1$ & $0$ & $1$ \\ 
$0$ & $1$ & $0$ & $0$ \\ 
$0$ & $0$ & $1$ & $0$ \\ 
$0$ & $0$ & $0$ & $0$%
\end{tabular}%
\end{equation*}%
In this case, the probability of the observer stating the value $1$ is the
sum of the probability of this occurring given all possible immediate parent
variable combinations, 
\begin{eqnarray*}
P\left( o^{1}\right)  &=&\sum_{i,j,k}P\left( o^{1},a^{i},f^{j},r^{k}\right) 
\\
&=&P\left( o^{1},a^{1},f^{1},r^{1}\right) +P\left(
o^{1},a^{1},f^{1},r^{0}\right) +P\left( o^{1},a^{0},f^{1},r^{1}\right)
+P\left( o^{1},a^{0},f^{0},r^{1}\right)  \\
&=&P\left( o^{1},a^{1},f^{1}\right) +P\left( o^{1},a^{0},r^{1}\right)  \\
&=&P\left( o^{1}\mid a^{1},f^{1}\right) P\left( a^{1},f^{1}\right) +P\left(
o^{1}\mid a^{0},r^{1}\right) P\left( a^{0},r^{1}\right) 
\end{eqnarray*}%
Here we may use the independence of the parent variables to simplify,%
\begin{eqnarray*}
P\left( o^{1}\right)  &=&P\left( o^{1}\mid a^{1},f^{1}\right) P\left(
a^{1}\right) P\left( f^{1}\right) +P\left( o^{1}\mid a^{0},r^{1}\right)
P\left( a^{0}\right) P\left( r^{1}\right)  \\
&=&\left( 1\right) \left( \beta \right) \left( \delta \right) +\left(
1\right) \left( 1-\beta \right) \left( \frac{1}{2}\right)  \\
&=&\beta \delta +\frac{1}{2}-\frac{1}{2}\beta  \\
&=&\beta \left( \delta -\frac{1}{2}\right) +\frac{1}{2}.
\end{eqnarray*}%
Similarly we find%
\begin{eqnarray*}
P\left( o^{0}\right)  &=&P\left( o^{0}\mid a^{1},f^{0}\right) P\left(
a^{1}\right) P\left( f^{0}\right) +P\left( o^{0}\mid a^{0},r^{0}\right)
P\left( a^{0}\right) P\left( r^{0}\right)  \\
&=&\left( 1\right) \left( \beta \right) \left( 1-\delta \right) +\left(
1\right) \left( 1-\beta \right) \left( \frac{1}{2}\right)  \\
&=&\beta \left( 1-\delta \right) +\frac{1}{2}-\frac{1}{2}\beta  \\
&=&\beta \left( \frac{1}{2}-\delta \right) +\frac{1}{2}.
\end{eqnarray*}%
We next compute%
\begin{eqnarray*}
P\left( a^{1}\mid o^{1}\right)  &=&\frac{P\left( a^{1},o^{1}\right) }{%
P\left( o^{1}\right) } \\
&=&\frac{P\left( o^{1}\mid a^{1}\right) P\left( a^{1}\right) }{P\left(
o^{1}\right) } \\
&=&\frac{\left[ P\left( o^{1}\mid a^{1},f^{1}\right) +P\left( o^{1}\mid
a^{1},f^{0}\right) \right] P\left( a^{1}\right) }{P\left( o^{1}\right) } \\
&=&\frac{\left[ 1+0\right] \beta }{\beta \left( \delta -\frac{1}{2}\right) +%
\frac{1}{2}} \\
&=&\frac{\beta }{\beta \left( \delta -\frac{1}{2}\right) +\frac{1}{2}} \\
&=&\frac{1}{\delta -\frac{1}{2}+\frac{1}{2\beta }}.
\end{eqnarray*}%
And similarly,%
\begin{eqnarray*}
P\left( a^{1}\mid o^{0}\right)  &=&\frac{P\left( a^{1},o^{0}\right) }{%
P\left( o^{0}\right) } \\
&=&\frac{P\left( o^{0}\mid a^{1}\right) P\left( a^{1}\right) }{P\left(
o^{0}\right) } \\
&=&\frac{\left[ P\left( o^{0}\mid a^{1},f^{0}\right) +P\left( o^{0}\mid
a^{1},f^{1}\right) \right] P\left( a^{1}\right) }{P\left( o^{0}\right) } \\
&=&\frac{\left[ 1+0\right] \beta }{\beta \left( \frac{1}{2}-\delta \right) +%
\frac{1}{2}} \\
&=&\frac{\beta }{\beta \left( \frac{1}{2}-\delta \right) +\frac{1}{2}} \\
&=&\frac{1}{\frac{1}{2}-\delta +\frac{1}{2\beta }}
\end{eqnarray*}

Now we wish to consider a Bayesian belief update where we use an observation
of $o$ to change our opinion about the value of $\beta $. We manipulate%
\begin{eqnarray*}
P\left( a^{1}\mid o^{0}\right)  &=&\frac{1}{\frac{1}{2}-\delta +\frac{1}{%
2\beta }} \\
\frac{1}{2\beta } &=&\frac{1}{P\left( a^{1}\mid o^{0}\right) }-\frac{1}{2}%
+\delta  \\
2\beta  &=&\frac{1}{\frac{1}{P\left( a^{1}\mid o^{0}\right) }-\frac{1}{2}%
+\delta } \\
\beta  &=&\frac{1}{2\left( \frac{1}{P\left( a^{1}\mid o^{0}\right) }-\frac{1%
}{2}+\delta \right) }
\end{eqnarray*}%
We do not know $\delta $, but using a consensus of multiple observers over
multiple draws of $f$ we can approximate it. We can start with a
uninformative prior (uniform over $\left[ 0,1\right] $) and update this via
Bayes theorem.

\bibliographystyle{amsplain}
\bibliography{acompat,JHU}

\end{document}
